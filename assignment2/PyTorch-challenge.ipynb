{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. CIFAR-10 open-ended challenge\n",
    "\n",
    "\n",
    "### Things you might try:\n",
    "- **Filter size**: Above we used 5x5; would smaller filters be more efficient?\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and other hyperparameters. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these, but don't miss the fun if you have time!\n",
    "\n",
    "- Alternative optimizers: you can try Adam, Adagrad, RMSprop, etc.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "### Have fun and happy training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:__main__:__main__: device=cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "from cs231n.hyperopt import *\n",
    "\n",
    "fs = '%(asctime)s %(levelname)s:%(message)s'\n",
    "ds = '%b  %-d %H:%M:%S'\n",
    "logging.basicConfig(format=fs, datefmt=ds)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "dtype = torch.float32\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "logger.debug(\"%s: device=%s\" % (__name__, device))\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN+NUM_VAL)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:visdom:Visdom successfully connected to server\n",
      "DEBUG:cs231n.hyperopt:optimize:\n",
      "DEBUG:cs231n.hyperopt:coarse_step:\n",
      "DEBUG:cs231n.train_utils:train:\n",
      "INFO:cs231n.train_utils:train: It 0, loss = 2.2912\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 11.28\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 11.90\n",
      "\n",
      "INFO:cs231n.train_utils:train: It 100, loss = nan\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 9.90\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 8.70\n",
      "\n",
      "INFO:cs231n.train_utils:train: It 101, loss = nan\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 9.46\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 8.70\n",
      "\n",
      "DEBUG:cs231n.train_utils:train:\n",
      "INFO:cs231n.train_utils:train: It 0, loss = 2.2951\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 8.59\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 9.90\n",
      "\n",
      "INFO:cs231n.train_utils:train: It 100, loss = 1.9424\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 35.33\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 35.70\n",
      "\n",
      "INFO:cs231n.train_utils:train: It 101, loss = 1.8279\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 34.11\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 36.10\n",
      "\n",
      "INFO:cs231n.hyperopt:coarse_step:\tlr = 1.00E-03\n",
      "INFO:cs231n.hyperopt:coarse_step:\t\tworking = True\n",
      "DEBUG:cs231n.hyperopt:fine_step:\n",
      "DEBUG:cs231n.train_utils:train:\n",
      "INFO:cs231n.train_utils:train: It 0, loss = 1.8496\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 34.72\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 35.40\n",
      "\n",
      "INFO:cs231n.train_utils:train: It 100, loss = 1.9061\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 39.24\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 40.00\n",
      "\n",
      "INFO:cs231n.train_utils:train: It 200, loss = 1.5378\n",
      "INFO:cs231n.train_utils:train: Train acc \t= 44.36\n",
      "INFO:cs231n.train_utils:train: Val acc \t= 45.70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(999)\n",
    "\n",
    "im_shape = (3, 32, 32)\n",
    "num_classes = 10\n",
    "\n",
    "choices = {\n",
    "        \"Architecture\": [\"batchnorm-relu-conv\"],\n",
    "        \"FilterSize\": [3, 5],\n",
    "        #\"FilterCount\": [8, 32, 64],\n",
    "        \"FilterCount\": [8, 32],\n",
    "        #\"Stride\": [1, 2],\n",
    "        \"Stride\": [1, 2],\n",
    "        #\"N\": [3, 5, 10],\n",
    "        \"N\": [3],\n",
    "        #\"M\": [1, 2],\n",
    "        \"M\": [1],\n",
    "        \"HiddenSize\": [1000],\n",
    "        \"Dropout\": [0.25, 0.5, 0.95]\n",
    "}\n",
    "\n",
    "# This one should sample exactly the network from assignment.\n",
    "#\"\"\"\n",
    "choices = {\n",
    "        \"Architecture\": [\"batchnorm-relu-conv\"],\n",
    "        \"FilterSize\": [3],\n",
    "        \"FilterCount\": [32],\n",
    "        \"Stride\": [1],\n",
    "        \"N\": [2],\n",
    "        \"M\": [1],\n",
    "        \"HiddenSize\": [1000],\n",
    "        \"Dropout\": [0.]\n",
    "}\n",
    "#\"\"\"\n",
    "\n",
    "ho = HyperOpt(choices, construct_model, train, loader_train, loader_val,\n",
    "              max_active=3, coarse_its=100, fine_epochs=5, verbose=True,\n",
    "              visualize=True, port=6006, device=device)\n",
    "\n",
    "ho.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you did \n",
    "\n",
    "In the cell below you should write an explanation of what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what you did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model). Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
