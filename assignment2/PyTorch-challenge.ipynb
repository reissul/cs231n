{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. CIFAR-10 open-ended challenge\n",
    "\n",
    "\n",
    "### Things you might try:\n",
    "- **Filter size**: Above we used 5x5; would smaller filters be more efficient?\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and other hyperparameters. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these, but don't miss the fun if you have time!\n",
    "\n",
    "- Alternative optimizers: you can try Adam, Adagrad, RMSprop, etc.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "### Have fun and happy training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:06:48 DEBUG:__main__: device=cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from cs231n.hyperopt import *\n",
    "\n",
    "fs = '%(asctime)s %(levelname)s:%(message)s'\n",
    "ds = '%b  %-d %H:%M:%S'\n",
    "logging.basicConfig(format=fs, datefmt=ds, level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "dtype = torch.float32\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "logger.debug(\"%s: device=%s\" % (__name__, device))\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN+NUM_VAL)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:06:55 INFO:Visdom successfully connected to server\n",
      "Sep  29 20:06:55 DEBUG:optimize: starting\n",
      "Sep  29 20:06:55 DEBUG:coarse_step: starting\n",
      "Sep  29 20:06:55 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (3): Dropout2d(p=0.5)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (7): Dropout2d(p=0.5)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (11): Dropout2d(p=0.5)\n",
      "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU()\n",
      "  (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (15): Dropout2d(p=0.5)\n",
      "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU()\n",
      "  (18): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (19): Dropout2d(p=0.5)\n",
      "  (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ReLU()\n",
      "  (22): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (23): Dropout2d(p=0.5)\n",
      "  (24): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (25): ReLU()\n",
      "  (26): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (27): Dropout2d(p=0.5)\n",
      "  (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU()\n",
      "  (30): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (31): Dropout2d(p=0.5)\n",
      "  (32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (33): ReLU()\n",
      "  (34): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (35): Dropout2d(p=0.5)\n",
      "  (36): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (37): ReLU()\n",
      "  (38): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (39): Dropout2d(p=0.5)\n",
      "  (40): Flatten()\n",
      "  (41): Linear(in_features=65536, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:06:55 DEBUG:train: starting\n",
      "Sep  29 20:07:02 INFO:train: Epoch 1/1, It 1/100, loss = 2.3566\n",
      "Sep  29 20:07:02 INFO:train: Train acc = 9.03\n",
      "Sep  29 20:07:02 INFO:train: Val acc = 10.70\n",
      "\n",
      "Sep  29 20:07:43 INFO:train: Epoch 1/1, It 100/100, loss = nan\n",
      "Sep  29 20:07:43 INFO:train: Train acc = 9.90\n",
      "Sep  29 20:07:43 INFO:train: Val acc = 8.70\n",
      "\n",
      "Sep  29 20:07:43 DEBUG:train: ending\n",
      "Sep  29 20:07:43 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (3): Dropout2d(p=0.5)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (7): Dropout2d(p=0.5)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (11): Dropout2d(p=0.5)\n",
      "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU()\n",
      "  (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (15): Dropout2d(p=0.5)\n",
      "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU()\n",
      "  (18): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (19): Dropout2d(p=0.5)\n",
      "  (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ReLU()\n",
      "  (22): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (23): Dropout2d(p=0.5)\n",
      "  (24): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (25): ReLU()\n",
      "  (26): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (27): Dropout2d(p=0.5)\n",
      "  (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU()\n",
      "  (30): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (31): Dropout2d(p=0.5)\n",
      "  (32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (33): ReLU()\n",
      "  (34): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (35): Dropout2d(p=0.5)\n",
      "  (36): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (37): ReLU()\n",
      "  (38): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (39): Dropout2d(p=0.5)\n",
      "  (40): Flatten()\n",
      "  (41): Linear(in_features=65536, out_features=10, bias=True)\n",
      ")\n",
      "Sep  29 20:07:43 DEBUG:train: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:07:48 INFO:train: Epoch 1/1, It 1/100, loss = 2.3199\n",
      "Sep  29 20:07:48 INFO:train: Train acc = 10.16\n",
      "Sep  29 20:07:48 INFO:train: Val acc = 11.90\n",
      "\n",
      "Sep  29 20:08:30 INFO:train: Epoch 1/1, It 100/100, loss = 2.2653\n",
      "Sep  29 20:08:30 INFO:train: Train acc = 10.33\n",
      "Sep  29 20:08:30 INFO:train: Val acc = 10.20\n",
      "\n",
      "Sep  29 20:08:30 DEBUG:train: ending\n",
      "Sep  29 20:08:30 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (3): Dropout2d(p=0.5)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (7): Dropout2d(p=0.5)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (11): Dropout2d(p=0.5)\n",
      "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU()\n",
      "  (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (15): Dropout2d(p=0.5)\n",
      "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU()\n",
      "  (18): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (19): Dropout2d(p=0.5)\n",
      "  (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ReLU()\n",
      "  (22): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (23): Dropout2d(p=0.5)\n",
      "  (24): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (25): ReLU()\n",
      "  (26): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (27): Dropout2d(p=0.5)\n",
      "  (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU()\n",
      "  (30): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (31): Dropout2d(p=0.5)\n",
      "  (32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (33): ReLU()\n",
      "  (34): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (35): Dropout2d(p=0.5)\n",
      "  (36): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (37): ReLU()\n",
      "  (38): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (39): Dropout2d(p=0.5)\n",
      "  (40): Flatten()\n",
      "  (41): Linear(in_features=65536, out_features=10, bias=True)\n",
      ")\n",
      "Sep  29 20:08:30 DEBUG:train: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = 2.3535255095009524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:08:35 INFO:train: Epoch 1/1, It 1/100, loss = 2.2971\n",
      "Sep  29 20:08:35 INFO:train: Train acc = 9.03\n",
      "Sep  29 20:08:35 INFO:train: Val acc = 7.80\n",
      "\n",
      "Sep  29 20:09:17 INFO:train: Epoch 1/1, It 100/100, loss = 2.3471\n",
      "Sep  29 20:09:17 INFO:train: Train acc = 9.98\n",
      "Sep  29 20:09:17 INFO:train: Val acc = 11.30\n",
      "\n",
      "Sep  29 20:09:17 DEBUG:train: ending\n",
      "Sep  29 20:09:17 DEBUG:coarse_step: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = -2.177018187434197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:09:18 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Dropout2d(p=0.05)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): Dropout2d(p=0.05)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): Dropout2d(p=0.05)\n",
      "  (12): Flatten()\n",
      "  (13): Linear(in_features=65536, out_features=1000, bias=True)\n",
      "  (14): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n",
      "Sep  29 20:09:18 DEBUG:train: starting\n",
      "Sep  29 20:09:19 INFO:train: Epoch 1/1, It 1/100, loss = 2.3138\n",
      "Sep  29 20:09:19 INFO:train: Train acc = 12.24\n",
      "Sep  29 20:09:19 INFO:train: Val acc = 10.20\n",
      "\n",
      "Sep  29 20:09:28 INFO:train: Epoch 1/1, It 100/100, loss = nan\n",
      "Sep  29 20:09:28 INFO:train: Train acc = 10.33\n",
      "Sep  29 20:09:28 INFO:train: Val acc = 8.70\n",
      "\n",
      "Sep  29 20:09:28 DEBUG:train: ending\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:09:29 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Dropout2d(p=0.05)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (7): Dropout2d(p=0.05)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): Dropout2d(p=0.05)\n",
      "  (12): Flatten()\n",
      "  (13): Linear(in_features=65536, out_features=1000, bias=True)\n",
      "  (14): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n",
      "Sep  29 20:09:29 DEBUG:train: starting\n",
      "Sep  29 20:09:30 INFO:train: Epoch 1/1, It 1/100, loss = 2.2947\n",
      "Sep  29 20:09:30 INFO:train: Train acc = 7.81\n",
      "Sep  29 20:09:30 INFO:train: Val acc = 9.80\n",
      "\n",
      "Sep  29 20:09:40 INFO:train: Epoch 1/1, It 100/100, loss = 1.3960\n",
      "Sep  29 20:09:40 INFO:train: Train acc = 46.88\n",
      "Sep  29 20:09:40 INFO:train: Val acc = 46.90\n",
      "\n",
      "Sep  29 20:09:40 DEBUG:train: ending\n",
      "Sep  29 20:09:40 INFO:coarse_step:lr = 1.00E-02\n",
      "Sep  29 20:09:40 DEBUG:coarse_step: starting\n",
      "Sep  29 20:09:40 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (3): Dropout2d(p=0.05)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (7): Dropout2d(p=0.05)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (11): Dropout2d(p=0.05)\n",
      "  (12): Flatten()\n",
      "  (13): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "Sep  29 20:09:40 DEBUG:train: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = 39.161203722732985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:09:41 INFO:train: Epoch 1/1, It 1/100, loss = 2.3136\n",
      "Sep  29 20:09:41 INFO:train: Train acc = 10.50\n",
      "Sep  29 20:09:41 INFO:train: Val acc = 10.90\n",
      "\n",
      "Sep  29 20:09:43 INFO:train: Epoch 1/1, It 100/100, loss = 1.6816\n",
      "Sep  29 20:09:43 INFO:train: Train acc = 40.28\n",
      "Sep  29 20:09:43 INFO:train: Val acc = 43.50\n",
      "\n",
      "Sep  29 20:09:43 DEBUG:train: ending\n",
      "Sep  29 20:09:43 INFO:coarse_step:lr = 1.00E-01\n",
      "Sep  29 20:09:43 DEBUG:coarse_step: starting\n",
      "Sep  29 20:09:43 DEBUG:coarse_step:Sequential(\n",
      "  (0): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (1): ReLU()\n",
      "  (2): Conv2d(3, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (3): Dropout2d(p=0.05)\n",
      "  (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (7): Dropout2d(p=0.05)\n",
      "  (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (9): ReLU()\n",
      "  (10): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (11): Dropout2d(p=0.05)\n",
      "  (12): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (13): ReLU()\n",
      "  (14): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (15): Dropout2d(p=0.05)\n",
      "  (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (17): ReLU()\n",
      "  (18): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (19): Dropout2d(p=0.05)\n",
      "  (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (21): ReLU()\n",
      "  (22): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (23): Dropout2d(p=0.05)\n",
      "  (24): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (25): ReLU()\n",
      "  (26): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (27): Dropout2d(p=0.05)\n",
      "  (28): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (29): ReLU()\n",
      "  (30): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (31): Dropout2d(p=0.05)\n",
      "  (32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (33): ReLU()\n",
      "  (34): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (35): Dropout2d(p=0.05)\n",
      "  (36): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (37): ReLU()\n",
      "  (38): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (39): Dropout2d(p=0.05)\n",
      "  (40): Flatten()\n",
      "  (41): Linear(in_features=1024, out_features=1000, bias=True)\n",
      "  (42): Linear(in_features=1000, out_features=10, bias=True)\n",
      ")\n",
      "Sep  29 20:09:43 DEBUG:train: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = 27.31800232086966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:09:44 INFO:train: Epoch 1/1, It 1/100, loss = 2.3025\n",
      "Sep  29 20:09:44 INFO:train: Train acc = 10.16\n",
      "Sep  29 20:09:44 INFO:train: Val acc = 10.70\n",
      "\n",
      "Sep  29 20:09:47 INFO:train: Epoch 1/1, It 100/100, loss = 2.1827\n",
      "Sep  29 20:09:47 INFO:train: Train acc = 21.44\n",
      "Sep  29 20:09:47 INFO:train: Val acc = 23.20\n",
      "\n",
      "Sep  29 20:09:47 DEBUG:train: ending\n",
      "Sep  29 20:09:47 INFO:coarse_step:lr = 1.00E-01\n",
      "Sep  29 20:09:47 DEBUG:fine_step: starting\n",
      "Sep  29 20:09:47 DEBUG:train: starting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc_dec = 5.203759158703927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sep  29 20:09:49 INFO:train: Epoch 1/5, It 1/766, loss = 1.6019\n",
      "Sep  29 20:09:49 INFO:train: Train acc = 43.66\n",
      "Sep  29 20:09:49 INFO:train: Val acc = 47.50\n",
      "\n",
      "Sep  29 20:09:58 INFO:train: Epoch 1/5, It 100/766, loss = 1.3735\n",
      "Sep  29 20:09:58 INFO:train: Train acc = 50.43\n",
      "Sep  29 20:09:58 INFO:train: Val acc = 48.70\n",
      "\n",
      "Sep  29 20:10:08 INFO:train: Epoch 1/5, It 200/766, loss = 1.3544\n",
      "Sep  29 20:10:08 INFO:train: Train acc = 53.39\n",
      "Sep  29 20:10:08 INFO:train: Val acc = 51.50\n",
      "\n",
      "Sep  29 20:10:18 INFO:train: Epoch 1/5, It 300/766, loss = 1.6619\n",
      "Sep  29 20:10:18 INFO:train: Train acc = 50.17\n",
      "Sep  29 20:10:18 INFO:train: Val acc = 52.60\n",
      "\n",
      "Sep  29 20:10:27 INFO:train: Epoch 1/5, It 400/766, loss = 1.3452\n",
      "Sep  29 20:10:27 INFO:train: Train acc = 56.94\n",
      "Sep  29 20:10:27 INFO:train: Val acc = 53.80\n",
      "\n",
      "Sep  29 20:10:37 INFO:train: Epoch 1/5, It 500/766, loss = 1.1134\n",
      "Sep  29 20:10:37 INFO:train: Train acc = 59.20\n",
      "Sep  29 20:10:37 INFO:train: Val acc = 58.50\n",
      "\n",
      "Sep  29 20:10:47 INFO:train: Epoch 1/5, It 600/766, loss = 0.9425\n",
      "Sep  29 20:10:47 INFO:train: Train acc = 59.20\n",
      "Sep  29 20:10:47 INFO:train: Val acc = 58.70\n",
      "\n",
      "Sep  29 20:10:57 INFO:train: Epoch 1/5, It 700/766, loss = 1.1525\n",
      "Sep  29 20:10:57 INFO:train: Train acc = 63.19\n",
      "Sep  29 20:10:57 INFO:train: Val acc = 62.30\n",
      "\n",
      "Sep  29 20:11:03 INFO:train: Epoch 1/5, It 766/766, loss = 0.9831\n",
      "Sep  29 20:11:03 INFO:train: Train acc = 65.54\n",
      "Sep  29 20:11:03 INFO:train: Val acc = 61.50\n",
      "\n",
      "Sep  29 20:11:05 INFO:train: Epoch 2/5, It 1/766, loss = 0.9101\n",
      "Sep  29 20:11:05 INFO:train: Train acc = 66.84\n",
      "Sep  29 20:11:05 INFO:train: Val acc = 62.30\n",
      "\n",
      "Sep  29 20:11:14 INFO:train: Epoch 2/5, It 100/766, loss = 0.8673\n",
      "Sep  29 20:11:14 INFO:train: Train acc = 64.58\n",
      "Sep  29 20:11:14 INFO:train: Val acc = 63.90\n",
      "\n",
      "Sep  29 20:11:24 INFO:train: Epoch 2/5, It 200/766, loss = 1.1191\n",
      "Sep  29 20:11:24 INFO:train: Train acc = 64.58\n",
      "Sep  29 20:11:24 INFO:train: Val acc = 60.90\n",
      "\n",
      "Sep  29 20:11:34 INFO:train: Epoch 2/5, It 300/766, loss = 0.7438\n",
      "Sep  29 20:11:34 INFO:train: Train acc = 67.10\n",
      "Sep  29 20:11:34 INFO:train: Val acc = 64.30\n",
      "\n",
      "Sep  29 20:11:43 INFO:train: Epoch 2/5, It 400/766, loss = 1.0084\n",
      "Sep  29 20:11:43 INFO:train: Train acc = 66.23\n",
      "Sep  29 20:11:43 INFO:train: Val acc = 60.90\n",
      "\n",
      "Sep  29 20:11:53 INFO:train: Epoch 2/5, It 500/766, loss = 0.7795\n",
      "Sep  29 20:11:53 INFO:train: Train acc = 63.28\n",
      "Sep  29 20:11:53 INFO:train: Val acc = 60.60\n",
      "\n",
      "Sep  29 20:12:03 INFO:train: Epoch 2/5, It 600/766, loss = 1.0197\n",
      "Sep  29 20:12:03 INFO:train: Train acc = 67.97\n",
      "Sep  29 20:12:03 INFO:train: Val acc = 62.70\n",
      "\n",
      "Sep  29 20:12:13 INFO:train: Epoch 2/5, It 700/766, loss = 0.9462\n",
      "Sep  29 20:12:13 INFO:train: Train acc = 69.53\n",
      "Sep  29 20:12:13 INFO:train: Val acc = 67.00\n",
      "\n",
      "Sep  29 20:12:19 INFO:train: Epoch 2/5, It 766/766, loss = 1.2628\n",
      "Sep  29 20:12:19 INFO:train: Train acc = 69.36\n",
      "Sep  29 20:12:19 INFO:train: Val acc = 66.80\n",
      "\n",
      "Sep  29 20:12:21 INFO:train: Epoch 3/5, It 1/766, loss = 0.5740\n",
      "Sep  29 20:12:21 INFO:train: Train acc = 72.92\n",
      "Sep  29 20:12:21 INFO:train: Val acc = 66.50\n",
      "\n",
      "Sep  29 20:12:30 INFO:train: Epoch 3/5, It 100/766, loss = 0.8333\n",
      "Sep  29 20:12:30 INFO:train: Train acc = 71.79\n",
      "Sep  29 20:12:30 INFO:train: Val acc = 65.40\n",
      "\n",
      "Sep  29 20:12:40 INFO:train: Epoch 3/5, It 200/766, loss = 1.1269\n",
      "Sep  29 20:12:40 INFO:train: Train acc = 69.27\n",
      "Sep  29 20:12:40 INFO:train: Val acc = 62.40\n",
      "\n",
      "Sep  29 20:12:50 INFO:train: Epoch 3/5, It 300/766, loss = 0.7278\n",
      "Sep  29 20:12:50 INFO:train: Train acc = 73.18\n",
      "Sep  29 20:12:50 INFO:train: Val acc = 65.60\n",
      "\n",
      "Sep  29 20:12:59 INFO:train: Epoch 3/5, It 400/766, loss = 0.7929\n",
      "Sep  29 20:12:59 INFO:train: Train acc = 71.61\n",
      "Sep  29 20:12:59 INFO:train: Val acc = 64.60\n",
      "\n",
      "Sep  29 20:13:09 INFO:train: Epoch 3/5, It 500/766, loss = 1.0402\n",
      "Sep  29 20:13:09 INFO:train: Train acc = 74.74\n",
      "Sep  29 20:13:09 INFO:train: Val acc = 66.50\n",
      "\n",
      "Sep  29 20:13:19 INFO:train: Epoch 3/5, It 600/766, loss = 0.7180\n",
      "Sep  29 20:13:19 INFO:train: Train acc = 65.71\n",
      "Sep  29 20:13:19 INFO:train: Val acc = 62.60\n",
      "\n",
      "Sep  29 20:13:29 INFO:train: Epoch 3/5, It 700/766, loss = 0.8769\n",
      "Sep  29 20:13:29 INFO:train: Train acc = 71.44\n",
      "Sep  29 20:13:29 INFO:train: Val acc = 65.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(999)\n",
    "\n",
    "im_shape = (3, 32, 32)\n",
    "num_classes = 10\n",
    "\n",
    "choices = {\n",
    "        \"Architecture\": [\"batchnorm-relu-conv\"],\n",
    "        \"FilterSize\": [3, 5],\n",
    "        \"FilterCount\": [8, 32, 64],\n",
    "        \"Stride\": [1, 2],\n",
    "        \"N\": [3, 5, 10],\n",
    "        \"M\": [1, 2],\n",
    "        \"HiddenSize\": [1000],\n",
    "        \"Dropout\": [0.05, 0.5, 0.95]\n",
    "}\n",
    "\n",
    "ho = HyperOpt(choices, construct_model, train, loader_train, loader_val,\n",
    "              max_active=3, coarse_its=100, fine_epochs=5, verbose=True,\n",
    "              visualize=True, port=6006, device=device)\n",
    "\n",
    "ho.optimize()\n",
    "\n",
    "plt.close('all') # play nice with Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you did \n",
    "\n",
    "In the cell below you should write an explanation of what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what you did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model). Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
