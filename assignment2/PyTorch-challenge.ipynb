{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V. CIFAR-10 open-ended challenge\n",
    "\n",
    "\n",
    "### Things you might try:\n",
    "- **Filter size**: Above we used 5x5; would smaller filters be more efficient?\n",
    "- **Number of filters**: Above we used 32 filters. Do more or fewer do better?\n",
    "- **Pooling vs Strided Convolution**: Do you use max pooling or just stride convolutions?\n",
    "- **Batch normalization**: Try adding spatial batch normalization after convolution layers and vanilla batch normalization after affine layers. Do your networks train faster?\n",
    "- **Network architecture**: The network above has two layers of trainable parameters. Can you do better with a deep network? Good architectures to try include:\n",
    "    - [conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [conv-relu-conv-relu-pool]xN -> [affine]xM -> [softmax or SVM]\n",
    "    - [batchnorm-relu-conv]xN -> [affine]xM -> [softmax or SVM]\n",
    "- **Global Average Pooling**: Instead of flattening and then having multiple affine layers, perform convolutions until your image gets small (7x7 or so) and then perform an average pooling operation to get to a 1x1 image picture (1, 1 , Filter#), which is then reshaped into a (Filter#) vector. This is used in [Google's Inception Network](https://arxiv.org/abs/1512.00567) (See Table 1 for their architecture).\n",
    "- **Regularization**: Add l2 weight regularization, or perhaps use Dropout.\n",
    "\n",
    "### Tips for training\n",
    "For each network architecture that you try, you should tune the learning rate and other hyperparameters. When doing this there are a couple important things to keep in mind:\n",
    "\n",
    "- If the parameters are working well, you should see improvement within a few hundred iterations\n",
    "- Remember the coarse-to-fine approach for hyperparameter tuning: start by testing a large range of hyperparameters for just a few training iterations to find the combinations of parameters that are working at all.\n",
    "- Once you have found some sets of parameters that seem to work, search more finely around these parameters. You may need to train for more epochs.\n",
    "- You should use the validation set for hyperparameter search, and save your test set for evaluating your architecture on the best parameters as selected by the validation set.\n",
    "\n",
    "### Going above and beyond\n",
    "If you are feeling adventurous there are many other features you can implement to try and improve your performance. You are **not required** to implement any of these, but don't miss the fun if you have time!\n",
    "\n",
    "- Alternative optimizers: you can try Adam, Adagrad, RMSprop, etc.\n",
    "- Alternative activation functions such as leaky ReLU, parametric ReLU, ELU, or MaxOut.\n",
    "- Model ensembles\n",
    "- Data augmentation\n",
    "- New Architectures\n",
    "  - [ResNets](https://arxiv.org/abs/1512.03385) where the input from the previous layer is added to the output.\n",
    "  - [DenseNets](https://arxiv.org/abs/1608.06993) where inputs into previous layers are concatenated together.\n",
    "  - [This blog has an in-depth overview](https://chatbotslife.com/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32)\n",
    "\n",
    "### Have fun and happy training! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Oct  1 01:24:09 DEBUG:__main__: device=cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from os.path import abspath\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from cs231n.hyperopt import *\n",
    "\n",
    "fs = '%(asctime)s %(levelname)s:%(message)s'\n",
    "ds = '%b  %-d %H:%M:%S'\n",
    "logging.basicConfig(format=fs, datefmt=ds, level=logging.DEBUG)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "logger.debug(\"%s: device=%s\" % (__name__, device))\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "NUM_VAL = 1000\n",
    "\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, NUM_TRAIN+NUM_VAL)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Oct  1 02:05:04 INFO:Visdom successfully connected to server\n",
      "Oct  1 02:05:04 DEBUG:load\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Oct  1 02:05:05 DEBUG:load\n",
      "Oct  1 02:05:05 DEBUG:load\n",
      "Oct  1 02:05:05 DEBUG:load\n",
      "Oct  1 02:05:05 DEBUG:load\n",
      "Oct  1 02:05:05 DEBUG:load\n",
      "Oct  1 02:05:06 DEBUG:optimize: entering\n",
      "Oct  1 02:05:06 DEBUG:fine_step: model002\n",
      "Oct  1 02:05:06 DEBUG:train: starting\n",
      "Oct  1 02:05:06 INFO:train: Epoch 1/5, It 1/766, loss = 0.9920\n",
      "Oct  1 02:05:06 INFO:train: Train acc = 59.55\n",
      "Oct  1 02:05:06 INFO:train: Val acc = 61.50\n",
      "\n",
      "Oct  1 02:05:09 INFO:train: Epoch 1/5, It 100/766, loss = 0.9775\n",
      "Oct  1 02:05:09 INFO:train: Train acc = 59.98\n",
      "Oct  1 02:05:09 INFO:train: Val acc = 59.30\n",
      "\n",
      "Oct  1 02:05:12 INFO:train: Epoch 1/5, It 200/766, loss = 1.2435\n",
      "Oct  1 02:05:12 INFO:train: Train acc = 61.63\n",
      "Oct  1 02:05:12 INFO:train: Val acc = 59.80\n",
      "\n",
      "Oct  1 02:05:16 INFO:train: Epoch 1/5, It 300/766, loss = 1.2973\n",
      "Oct  1 02:05:16 INFO:train: Train acc = 58.07\n",
      "Oct  1 02:05:16 INFO:train: Val acc = 60.40\n",
      "\n",
      "Oct  1 02:05:19 INFO:train: Epoch 1/5, It 400/766, loss = 1.1517\n",
      "Oct  1 02:05:19 INFO:train: Train acc = 61.81\n",
      "Oct  1 02:05:19 INFO:train: Val acc = 60.30\n",
      "\n",
      "Oct  1 02:05:22 INFO:train: Epoch 1/5, It 500/766, loss = 1.1043\n",
      "Oct  1 02:05:22 INFO:train: Train acc = 63.19\n",
      "Oct  1 02:05:22 INFO:train: Val acc = 58.60\n",
      "\n",
      "Oct  1 02:05:25 INFO:train: Epoch 1/5, It 600/766, loss = 1.1029\n",
      "Oct  1 02:05:25 INFO:train: Train acc = 60.50\n",
      "Oct  1 02:05:25 INFO:train: Val acc = 56.80\n",
      "\n",
      "Oct  1 02:05:29 INFO:train: Epoch 1/5, It 700/766, loss = 1.2584\n",
      "Oct  1 02:05:29 INFO:train: Train acc = 61.46\n",
      "Oct  1 02:05:29 INFO:train: Val acc = 61.70\n",
      "\n",
      "Oct  1 02:05:31 INFO:train: Epoch 1/5, It 766/766, loss = 1.4493\n",
      "Oct  1 02:05:31 INFO:train: Train acc = 58.25\n",
      "Oct  1 02:05:31 INFO:train: Val acc = 54.90\n",
      "\n",
      "Oct  1 02:05:31 DEBUG:save\n",
      "Oct  1 02:05:31 INFO:train: Epoch 2/5, It 1/766, loss = 1.0047\n",
      "Oct  1 02:05:31 INFO:train: Train acc = 61.46\n",
      "Oct  1 02:05:31 INFO:train: Val acc = 56.90\n",
      "\n",
      "Oct  1 02:05:35 INFO:train: Epoch 2/5, It 100/766, loss = 1.1232\n",
      "Oct  1 02:05:35 INFO:train: Train acc = 63.63\n",
      "Oct  1 02:05:35 INFO:train: Val acc = 63.20\n",
      "\n",
      "Oct  1 02:05:38 INFO:train: Epoch 2/5, It 200/766, loss = 1.0715\n",
      "Oct  1 02:05:38 INFO:train: Train acc = 63.11\n",
      "Oct  1 02:05:38 INFO:train: Val acc = 59.70\n",
      "\n",
      "Oct  1 02:05:41 INFO:train: Epoch 2/5, It 300/766, loss = 0.8946\n",
      "Oct  1 02:05:41 INFO:train: Train acc = 64.50\n",
      "Oct  1 02:05:41 INFO:train: Val acc = 63.10\n",
      "\n",
      "Oct  1 02:05:44 INFO:train: Epoch 2/5, It 400/766, loss = 0.7207\n",
      "Oct  1 02:05:44 INFO:train: Train acc = 64.50\n",
      "Oct  1 02:05:44 INFO:train: Val acc = 60.70\n",
      "\n",
      "Oct  1 02:05:47 INFO:train: Epoch 2/5, It 500/766, loss = 1.0219\n",
      "Oct  1 02:05:47 INFO:train: Train acc = 59.46\n",
      "Oct  1 02:05:47 INFO:train: Val acc = 59.30\n",
      "\n",
      "Oct  1 02:05:51 INFO:train: Epoch 2/5, It 600/766, loss = 0.9703\n",
      "Oct  1 02:05:51 INFO:train: Train acc = 59.03\n",
      "Oct  1 02:05:51 INFO:train: Val acc = 57.80\n",
      "\n",
      "Oct  1 02:05:54 INFO:train: Epoch 2/5, It 700/766, loss = 1.1611\n",
      "Oct  1 02:05:54 INFO:train: Train acc = 61.02\n",
      "Oct  1 02:05:54 INFO:train: Val acc = 63.70\n",
      "\n",
      "Oct  1 02:05:56 INFO:train: Epoch 2/5, It 766/766, loss = 0.8745\n",
      "Oct  1 02:05:56 INFO:train: Train acc = 62.07\n",
      "Oct  1 02:05:56 INFO:train: Val acc = 59.40\n",
      "\n",
      "Oct  1 02:05:56 DEBUG:save\n",
      "Oct  1 02:05:57 INFO:train: Epoch 3/5, It 1/766, loss = 1.0362\n",
      "Oct  1 02:05:57 INFO:train: Train acc = 61.20\n",
      "Oct  1 02:05:57 INFO:train: Val acc = 59.70\n",
      "\n",
      "Oct  1 02:06:00 INFO:train: Epoch 3/5, It 100/766, loss = 0.9740\n",
      "Oct  1 02:06:00 INFO:train: Train acc = 61.46\n",
      "Oct  1 02:06:00 INFO:train: Val acc = 59.20\n",
      "\n",
      "Oct  1 02:06:03 INFO:train: Epoch 3/5, It 200/766, loss = 1.0077\n",
      "Oct  1 02:06:03 INFO:train: Train acc = 62.67\n",
      "Oct  1 02:06:03 INFO:train: Val acc = 61.50\n",
      "\n",
      "Oct  1 02:06:06 INFO:train: Epoch 3/5, It 300/766, loss = 0.8802\n",
      "Oct  1 02:06:06 INFO:train: Train acc = 57.29\n",
      "Oct  1 02:06:06 INFO:train: Val acc = 54.40\n",
      "\n",
      "Oct  1 02:06:09 INFO:train: Epoch 3/5, It 400/766, loss = 0.8593\n",
      "Oct  1 02:06:09 INFO:train: Train acc = 56.86\n",
      "Oct  1 02:06:09 INFO:train: Val acc = 53.50\n",
      "\n",
      "Oct  1 02:06:13 INFO:train: Epoch 3/5, It 500/766, loss = 0.8519\n",
      "Oct  1 02:06:13 INFO:train: Train acc = 67.36\n",
      "Oct  1 02:06:13 INFO:train: Val acc = 62.90\n",
      "\n",
      "Oct  1 02:06:16 INFO:train: Epoch 3/5, It 600/766, loss = 1.0111\n",
      "Oct  1 02:06:16 INFO:train: Train acc = 61.81\n",
      "Oct  1 02:06:16 INFO:train: Val acc = 62.10\n",
      "\n",
      "Oct  1 02:06:19 INFO:train: Epoch 3/5, It 700/766, loss = 0.9224\n",
      "Oct  1 02:06:19 INFO:train: Train acc = 57.55\n",
      "Oct  1 02:06:19 INFO:train: Val acc = 56.60\n",
      "\n",
      "Oct  1 02:06:21 INFO:train: Epoch 3/5, It 766/766, loss = 0.9363\n",
      "Oct  1 02:06:21 INFO:train: Train acc = 63.37\n",
      "Oct  1 02:06:21 INFO:train: Val acc = 62.70\n",
      "\n",
      "Oct  1 02:06:21 DEBUG:save\n",
      "Oct  1 02:06:22 INFO:train: Epoch 4/5, It 1/766, loss = 0.5665\n",
      "Oct  1 02:06:22 INFO:train: Train acc = 61.37\n",
      "Oct  1 02:06:22 INFO:train: Val acc = 60.90\n",
      "\n",
      "Oct  1 02:06:25 INFO:train: Epoch 4/5, It 100/766, loss = 1.0463\n",
      "Oct  1 02:06:25 INFO:train: Train acc = 67.27\n",
      "Oct  1 02:06:25 INFO:train: Val acc = 62.90\n",
      "\n",
      "Oct  1 02:06:28 INFO:train: Epoch 4/5, It 200/766, loss = 0.9230\n",
      "Oct  1 02:06:28 INFO:train: Train acc = 64.06\n",
      "Oct  1 02:06:28 INFO:train: Val acc = 64.40\n",
      "\n",
      "Oct  1 02:06:32 INFO:train: Epoch 4/5, It 300/766, loss = 0.7943\n",
      "Oct  1 02:06:32 INFO:train: Train acc = 66.58\n",
      "Oct  1 02:06:32 INFO:train: Val acc = 60.90\n",
      "\n",
      "Oct  1 02:06:35 INFO:train: Epoch 4/5, It 400/766, loss = 0.9843\n",
      "Oct  1 02:06:35 INFO:train: Train acc = 65.62\n",
      "Oct  1 02:06:35 INFO:train: Val acc = 60.80\n",
      "\n",
      "Oct  1 02:06:38 INFO:train: Epoch 4/5, It 500/766, loss = 0.8822\n",
      "Oct  1 02:06:38 INFO:train: Train acc = 66.93\n",
      "Oct  1 02:06:38 INFO:train: Val acc = 60.40\n",
      "\n",
      "Oct  1 02:06:41 INFO:train: Epoch 4/5, It 600/766, loss = 0.9425\n",
      "Oct  1 02:06:41 INFO:train: Train acc = 64.41\n",
      "Oct  1 02:06:41 INFO:train: Val acc = 62.30\n",
      "\n",
      "Oct  1 02:06:44 INFO:train: Epoch 4/5, It 700/766, loss = 0.8146\n",
      "Oct  1 02:06:44 INFO:train: Train acc = 66.41\n",
      "Oct  1 02:06:45 INFO:train: Val acc = 66.00\n",
      "\n",
      "Oct  1 02:06:47 INFO:train: Epoch 4/5, It 766/766, loss = 1.0652\n",
      "Oct  1 02:06:47 INFO:train: Train acc = 60.07\n",
      "Oct  1 02:06:47 INFO:train: Val acc = 56.00\n",
      "\n",
      "Oct  1 02:06:47 DEBUG:save\n",
      "Oct  1 02:06:47 INFO:train: Epoch 5/5, It 1/766, loss = 0.9809\n",
      "Oct  1 02:06:47 INFO:train: Train acc = 59.29\n",
      "Oct  1 02:06:47 INFO:train: Val acc = 55.40\n",
      "\n",
      "Oct  1 02:06:51 INFO:train: Epoch 5/5, It 100/766, loss = 0.8943\n",
      "Oct  1 02:06:51 INFO:train: Train acc = 67.10\n",
      "Oct  1 02:06:51 INFO:train: Val acc = 62.70\n",
      "\n",
      "Oct  1 02:06:54 INFO:train: Epoch 5/5, It 200/766, loss = 1.1103\n",
      "Oct  1 02:06:54 INFO:train: Train acc = 62.59\n",
      "Oct  1 02:06:54 INFO:train: Val acc = 61.90\n",
      "\n",
      "Oct  1 02:06:57 INFO:train: Epoch 5/5, It 300/766, loss = 1.1108\n",
      "Oct  1 02:06:57 INFO:train: Train acc = 63.72\n",
      "Oct  1 02:06:57 INFO:train: Val acc = 60.40\n",
      "\n",
      "Oct  1 02:07:00 INFO:train: Epoch 5/5, It 400/766, loss = 1.1282\n",
      "Oct  1 02:07:00 INFO:train: Train acc = 62.15\n",
      "Oct  1 02:07:00 INFO:train: Val acc = 61.50\n",
      "\n",
      "Oct  1 02:07:04 INFO:train: Epoch 5/5, It 500/766, loss = 0.9268\n",
      "Oct  1 02:07:04 INFO:train: Train acc = 66.58\n",
      "Oct  1 02:07:04 INFO:train: Val acc = 66.50\n",
      "\n",
      "Oct  1 02:07:07 INFO:train: Epoch 5/5, It 600/766, loss = 1.0888\n",
      "Oct  1 02:07:07 INFO:train: Train acc = 65.10\n",
      "Oct  1 02:07:07 INFO:train: Val acc = 62.10\n",
      "\n",
      "Oct  1 02:07:10 INFO:train: Epoch 5/5, It 700/766, loss = 1.1171\n",
      "Oct  1 02:07:10 INFO:train: Train acc = 67.36\n",
      "Oct  1 02:07:10 INFO:train: Val acc = 62.80\n",
      "\n",
      "Oct  1 02:07:12 INFO:train: Epoch 5/5, It 766/766, loss = 0.7511\n",
      "Oct  1 02:07:12 INFO:train: Train acc = 69.88\n",
      "Oct  1 02:07:12 INFO:train: Val acc = 66.10\n",
      "\n",
      "Oct  1 02:07:12 DEBUG:save\n",
      "Oct  1 02:07:14 DEBUG:train: ending\n",
      "Oct  1 02:07:14 DEBUG:fine_step: model017\n",
      "Oct  1 02:07:14 DEBUG:train: starting\n",
      "Oct  1 02:07:16 INFO:train: Epoch 1/5, It 1/766, loss = 1.9288\n",
      "Oct  1 02:07:16 INFO:train: Train acc = 28.39\n",
      "Oct  1 02:07:16 INFO:train: Val acc = 30.30\n",
      "\n",
      "Oct  1 02:07:32 INFO:train: Epoch 1/5, It 100/766, loss = 1.6946\n",
      "Oct  1 02:07:32 INFO:train: Train acc = 39.58\n",
      "Oct  1 02:07:32 INFO:train: Val acc = 41.70\n",
      "\n",
      "Oct  1 02:07:48 INFO:train: Epoch 1/5, It 200/766, loss = 1.7531\n",
      "Oct  1 02:07:48 INFO:train: Train acc = 44.53\n",
      "Oct  1 02:07:48 INFO:train: Val acc = 44.20\n",
      "\n",
      "Oct  1 02:08:05 INFO:train: Epoch 1/5, It 300/766, loss = 1.5027\n",
      "Oct  1 02:08:05 INFO:train: Train acc = 43.23\n",
      "Oct  1 02:08:05 INFO:train: Val acc = 45.50\n",
      "\n",
      "Oct  1 02:08:21 INFO:train: Epoch 1/5, It 400/766, loss = 1.6187\n",
      "Oct  1 02:08:21 INFO:train: Train acc = 46.88\n",
      "Oct  1 02:08:21 INFO:train: Val acc = 48.00\n",
      "\n",
      "Oct  1 02:08:37 INFO:train: Epoch 1/5, It 500/766, loss = 1.4035\n",
      "Oct  1 02:08:37 INFO:train: Train acc = 47.22\n",
      "Oct  1 02:08:37 INFO:train: Val acc = 50.40\n",
      "\n",
      "Oct  1 02:08:54 INFO:train: Epoch 1/5, It 600/766, loss = 1.4479\n",
      "Oct  1 02:08:54 INFO:train: Train acc = 54.77\n",
      "Oct  1 02:08:54 INFO:train: Val acc = 57.30\n",
      "\n",
      "Oct  1 02:09:10 INFO:train: Epoch 1/5, It 700/766, loss = 1.5888\n",
      "Oct  1 02:09:10 INFO:train: Train acc = 56.25\n",
      "Oct  1 02:09:10 INFO:train: Val acc = 55.70\n",
      "\n",
      "Oct  1 02:09:21 INFO:train: Epoch 1/5, It 766/766, loss = 1.2376\n",
      "Oct  1 02:09:21 INFO:train: Train acc = 54.60\n",
      "Oct  1 02:09:21 INFO:train: Val acc = 54.60\n",
      "\n",
      "Oct  1 02:09:21 DEBUG:save\n",
      "Oct  1 02:09:24 INFO:train: Epoch 2/5, It 1/766, loss = 1.3103\n",
      "Oct  1 02:09:24 INFO:train: Train acc = 47.74\n",
      "Oct  1 02:09:24 INFO:train: Val acc = 50.50\n",
      "\n",
      "Oct  1 02:09:40 INFO:train: Epoch 2/5, It 100/766, loss = 1.0866\n",
      "Oct  1 02:09:40 INFO:train: Train acc = 54.51\n",
      "Oct  1 02:09:40 INFO:train: Val acc = 52.80\n",
      "\n",
      "Oct  1 02:09:56 INFO:train: Epoch 2/5, It 200/766, loss = 1.1343\n",
      "Oct  1 02:09:56 INFO:train: Train acc = 55.99\n",
      "Oct  1 02:09:56 INFO:train: Val acc = 57.90\n",
      "\n",
      "Oct  1 02:10:13 INFO:train: Epoch 2/5, It 300/766, loss = 1.0300\n",
      "Oct  1 02:10:13 INFO:train: Train acc = 40.19\n",
      "Oct  1 02:10:13 INFO:train: Val acc = 38.80\n",
      "\n",
      "Oct  1 02:10:29 INFO:train: Epoch 2/5, It 400/766, loss = 1.1163\n",
      "Oct  1 02:10:29 INFO:train: Train acc = 59.46\n",
      "Oct  1 02:10:29 INFO:train: Val acc = 57.40\n",
      "\n",
      "Oct  1 02:10:45 INFO:train: Epoch 2/5, It 500/766, loss = 1.0118\n",
      "Oct  1 02:10:45 INFO:train: Train acc = 59.90\n",
      "Oct  1 02:10:45 INFO:train: Val acc = 60.60\n",
      "\n",
      "Oct  1 02:11:02 INFO:train: Epoch 2/5, It 600/766, loss = 1.0820\n",
      "Oct  1 02:11:02 INFO:train: Train acc = 60.68\n",
      "Oct  1 02:11:02 INFO:train: Val acc = 60.40\n",
      "\n",
      "Oct  1 02:11:18 INFO:train: Epoch 2/5, It 700/766, loss = 1.0761\n",
      "Oct  1 02:11:18 INFO:train: Train acc = 65.97\n",
      "Oct  1 02:11:18 INFO:train: Val acc = 64.70\n",
      "\n",
      "Oct  1 02:11:29 INFO:train: Epoch 2/5, It 766/766, loss = 1.0687\n",
      "Oct  1 02:11:29 INFO:train: Train acc = 66.23\n",
      "Oct  1 02:11:29 INFO:train: Val acc = 65.20\n",
      "\n",
      "Oct  1 02:11:29 DEBUG:save\n",
      "Oct  1 02:11:32 INFO:train: Epoch 3/5, It 1/766, loss = 1.1892\n",
      "Oct  1 02:11:32 INFO:train: Train acc = 67.80\n",
      "Oct  1 02:11:32 INFO:train: Val acc = 65.30\n",
      "\n",
      "Oct  1 02:11:48 INFO:train: Epoch 3/5, It 100/766, loss = 0.8017\n",
      "Oct  1 02:11:48 INFO:train: Train acc = 65.10\n",
      "Oct  1 02:11:48 INFO:train: Val acc = 64.00\n",
      "\n",
      "Oct  1 02:12:04 INFO:train: Epoch 3/5, It 200/766, loss = 0.8636\n",
      "Oct  1 02:12:04 INFO:train: Train acc = 64.67\n",
      "Oct  1 02:12:04 INFO:train: Val acc = 63.40\n",
      "\n",
      "Oct  1 02:12:21 INFO:train: Epoch 3/5, It 300/766, loss = 1.2952\n",
      "Oct  1 02:12:21 INFO:train: Train acc = 67.36\n",
      "Oct  1 02:12:21 INFO:train: Val acc = 63.30\n",
      "\n",
      "Oct  1 02:12:37 INFO:train: Epoch 3/5, It 400/766, loss = 0.9042\n",
      "Oct  1 02:12:37 INFO:train: Train acc = 60.68\n",
      "Oct  1 02:12:37 INFO:train: Val acc = 58.60\n",
      "\n",
      "Oct  1 02:12:53 INFO:train: Epoch 3/5, It 500/766, loss = 0.7873\n",
      "Oct  1 02:12:53 INFO:train: Train acc = 66.15\n",
      "Oct  1 02:12:53 INFO:train: Val acc = 66.50\n",
      "\n",
      "Oct  1 02:13:10 INFO:train: Epoch 3/5, It 600/766, loss = 0.8160\n",
      "Oct  1 02:13:10 INFO:train: Train acc = 71.27\n",
      "Oct  1 02:13:10 INFO:train: Val acc = 65.70\n",
      "\n",
      "Oct  1 02:13:26 INFO:train: Epoch 3/5, It 700/766, loss = 0.6648\n",
      "Oct  1 02:13:26 INFO:train: Train acc = 65.54\n",
      "Oct  1 02:13:26 INFO:train: Val acc = 63.70\n",
      "\n",
      "Oct  1 02:13:37 INFO:train: Epoch 3/5, It 766/766, loss = 1.0267\n",
      "Oct  1 02:13:37 INFO:train: Train acc = 68.92\n",
      "Oct  1 02:13:37 INFO:train: Val acc = 67.90\n",
      "\n",
      "Oct  1 02:13:37 DEBUG:save\n",
      "Oct  1 02:13:39 INFO:train: Epoch 4/5, It 1/766, loss = 0.8206\n",
      "Oct  1 02:13:39 INFO:train: Train acc = 70.40\n",
      "Oct  1 02:13:39 INFO:train: Val acc = 67.80\n",
      "\n",
      "Oct  1 02:13:56 INFO:train: Epoch 4/5, It 100/766, loss = 0.6815\n",
      "Oct  1 02:13:56 INFO:train: Train acc = 64.67\n",
      "Oct  1 02:13:56 INFO:train: Val acc = 61.90\n",
      "\n",
      "Oct  1 02:14:12 INFO:train: Epoch 4/5, It 200/766, loss = 0.7301\n",
      "Oct  1 02:14:12 INFO:train: Train acc = 71.01\n",
      "Oct  1 02:14:12 INFO:train: Val acc = 67.10\n",
      "\n",
      "Oct  1 02:14:28 INFO:train: Epoch 4/5, It 300/766, loss = 0.8642\n",
      "Oct  1 02:14:28 INFO:train: Train acc = 69.53\n",
      "Oct  1 02:14:28 INFO:train: Val acc = 68.70\n",
      "\n",
      "Oct  1 02:14:45 INFO:train: Epoch 4/5, It 400/766, loss = 0.7940\n",
      "Oct  1 02:14:45 INFO:train: Train acc = 72.66\n",
      "Oct  1 02:14:45 INFO:train: Val acc = 68.60\n",
      "\n",
      "Oct  1 02:15:01 INFO:train: Epoch 4/5, It 500/766, loss = 0.8362\n",
      "Oct  1 02:15:01 INFO:train: Train acc = 72.05\n",
      "Oct  1 02:15:01 INFO:train: Val acc = 67.60\n",
      "\n",
      "Oct  1 02:15:18 INFO:train: Epoch 4/5, It 600/766, loss = 0.6906\n",
      "Oct  1 02:15:18 INFO:train: Train acc = 72.66\n",
      "Oct  1 02:15:18 INFO:train: Val acc = 69.90\n",
      "\n",
      "Oct  1 02:15:34 INFO:train: Epoch 4/5, It 700/766, loss = 0.8710\n",
      "Oct  1 02:15:34 INFO:train: Train acc = 73.61\n",
      "Oct  1 02:15:34 INFO:train: Val acc = 69.90\n",
      "\n",
      "Oct  1 02:15:46 INFO:train: Epoch 4/5, It 766/766, loss = 0.7797\n",
      "Oct  1 02:15:46 INFO:train: Train acc = 74.22\n",
      "Oct  1 02:15:46 INFO:train: Val acc = 69.90\n",
      "\n",
      "Oct  1 02:15:46 DEBUG:save\n",
      "Oct  1 02:15:48 INFO:train: Epoch 5/5, It 1/766, loss = 0.6611\n",
      "Oct  1 02:15:48 INFO:train: Train acc = 71.27\n",
      "Oct  1 02:15:48 INFO:train: Val acc = 69.00\n",
      "\n",
      "Oct  1 02:16:04 INFO:train: Epoch 5/5, It 100/766, loss = 0.9713\n",
      "Oct  1 02:16:04 INFO:train: Train acc = 74.48\n",
      "Oct  1 02:16:04 INFO:train: Val acc = 71.70\n",
      "\n",
      "Oct  1 02:16:21 INFO:train: Epoch 5/5, It 200/766, loss = 0.7825\n",
      "Oct  1 02:16:21 INFO:train: Train acc = 74.83\n",
      "Oct  1 02:16:21 INFO:train: Val acc = 69.80\n",
      "\n",
      "Oct  1 02:16:37 INFO:train: Epoch 5/5, It 300/766, loss = 0.4946\n",
      "Oct  1 02:16:37 INFO:train: Train acc = 75.00\n",
      "Oct  1 02:16:37 INFO:train: Val acc = 68.50\n",
      "\n",
      "Oct  1 02:16:53 INFO:train: Epoch 5/5, It 400/766, loss = 0.8780\n",
      "Oct  1 02:16:53 INFO:train: Train acc = 73.00\n",
      "Oct  1 02:16:53 INFO:train: Val acc = 68.60\n",
      "\n",
      "Oct  1 02:17:10 INFO:train: Epoch 5/5, It 500/766, loss = 0.6523\n",
      "Oct  1 02:17:10 INFO:train: Train acc = 73.61\n",
      "Oct  1 02:17:10 INFO:train: Val acc = 70.50\n",
      "\n",
      "Oct  1 02:17:26 INFO:train: Epoch 5/5, It 600/766, loss = 0.6062\n",
      "Oct  1 02:17:26 INFO:train: Train acc = 74.05\n",
      "Oct  1 02:17:26 INFO:train: Val acc = 70.20\n",
      "\n",
      "Oct  1 02:17:42 INFO:train: Epoch 5/5, It 700/766, loss = 0.8922\n",
      "Oct  1 02:17:42 INFO:train: Train acc = 76.13\n",
      "Oct  1 02:17:42 INFO:train: Val acc = 71.20\n",
      "\n",
      "Oct  1 02:17:54 INFO:train: Epoch 5/5, It 766/766, loss = 1.0173\n",
      "Oct  1 02:17:54 INFO:train: Train acc = 74.31\n",
      "Oct  1 02:17:54 INFO:train: Val acc = 68.10\n",
      "\n",
      "Oct  1 02:17:54 DEBUG:save\n",
      "Oct  1 02:17:56 DEBUG:train: ending\n",
      "Oct  1 02:17:56 DEBUG:fine_step: model004\n",
      "Oct  1 02:17:56 DEBUG:train: starting\n",
      "Oct  1 02:17:59 INFO:train: Epoch 1/5, It 1/766, loss = 2.1060\n",
      "Oct  1 02:17:59 INFO:train: Train acc = 21.96\n",
      "Oct  1 02:17:59 INFO:train: Val acc = 21.60\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-356d367fcea7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m               max_coarse=3, coarse_its=100, fine_epochs=5, device=device)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#plt.close('all') # play nice with Jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/cs231n/assignment2/cs231n/hyperopt.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoarse_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcoarse_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/cs231n/assignment2/cs231n/hyperopt.py\u001b[0m in \u001b[0;36mfine_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m         check = self.trainer(self.loader_train, self.loader_val, check.model, check.optimizer,\n\u001b[1;32m    119\u001b[0m                              \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                              epochs=self.fine_epochs, eval_iterations=16, device=self.device)\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_trained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/cs231n/assignment2/cs231n/train_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader_train, loader_val, model, optimizer, logdir, log_every, verbose, vis, epochs, iterations, eval_iterations, device)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_ACCS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%f\\n\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVAL_ACCS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%f\\n\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/cs231n/assignment2/cs231n/train_utils.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(loader, model, device, iterations)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mnum_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mnum_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mit\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.manual_seed(999)\n",
    "\n",
    "im_shape = (3, 32, 32)\n",
    "num_classes = 10\n",
    "\n",
    "choices = {\n",
    "        \"Architecture\": [\"batchnorm-relu-conv\"],\n",
    "        \"FilterSize\": [3, 5],\n",
    "        \"FilterCount\": [8, 32, 64],\n",
    "        \"Stride\": [2],\n",
    "        \"N\": [5, 10],\n",
    "        \"M\": [1, 2],\n",
    "        \"HiddenSize\": [1000],\n",
    "        \"Dropout\": [0., 0.5]# 0.95]\n",
    "}\n",
    "\n",
    "ho = HyperOpt(choices, construct_model, train, loader_train, loader_val, abspath(\"./logdir\"), \n",
    "              max_coarse=3, coarse_its=100, fine_epochs=5, device=device)\n",
    "\n",
    "ho.optimize()\n",
    "\n",
    "#plt.close('all') # play nice with Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize current logs.\n",
    "v = Visualizer(\"./logdir\")\n",
    "v.update(table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run a single model\n",
    "v = Visualizer(\"./logdir\")\n",
    "model = Model()\n",
    "model.train()\n",
    "train(choices, construct_model, train, loader_train, loader_val, abspath(\"./logdir\"), \n",
    "      max_coarse=3, coarse_its=100, fine_epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe what you did \n",
    "\n",
    "In the cell below you should write an explanation of what you did, any additional features that you implemented, and/or any graphs that you made in the process of training and evaluating your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Describe what you did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set -- run this only once\n",
    "\n",
    "Now that we've gotten a result we're happy with, we test our final model on the test set (which you should store in best_model). Think about how this compares to your validation set accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_model = model\n",
    "check_accuracy_part34(loader_test, best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
